{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from treeffuser import Treeffuser\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    HistGradientBoostingClassifier,\n",
    "    HistGradientBoostingRegressor,\n",
    ")\n",
    "from sklearn.model_selection import cross_val_predict, LeaveOneOut\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, mean_squared_error, roc_auc_score\n",
    "\n",
    "from data import load_amp, load_uke, GENERATIVE_COLUMNS\n",
    "\n",
    "X_amp, covariates_amp = load_amp(\n",
    "    \"../data/updrs_amp_all.csv\", sample_one_measurement_per_subject=True\n",
    ")\n",
    "X_amp[GENERATIVE_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uke, covariates_uke, extra_data_uke, y_uke = load_uke(\"../data/pdq_uke_new.csv\")\n",
    "\n",
    "valid_measurements = (~pd.isna(x_uke[\"PDQ\"])) & (~pd.isna(y_uke[\"PDQ\"]))\n",
    "x_uke = x_uke[valid_measurements]\n",
    "covariates_uke = covariates_uke[valid_measurements]\n",
    "extra_data_uke = extra_data_uke[valid_measurements]\n",
    "y_uke = y_uke[valid_measurements]\n",
    "\n",
    "x_uke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_covariates = pd.concat((\n",
    "    covariates_uke.reset_index(names=\"Subject\").melt(id_vars=\"Subject\", var_name=\"Covariate\", value_name=\"Value\").assign(Cohort=\"UKE\"),\n",
    "    covariates_amp.reset_index(names=\"Subject\").melt(id_vars=\"Subject\", var_name=\"Covariate\", value_name=\"Value\").assign(Cohort=\"AMP\"),\n",
    "), ignore_index=True)\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    \n",
    "    covariates = agg_covariates.groupby(\"Covariate\")\n",
    "    fig, axes = plt.subplots(1, len(covariates), figsize=(5 * len(covariates), 5))\n",
    "    for (covariate, covariate_data), ax in zip(covariates, axes):\n",
    "        sns.histplot(covariate_data, x=\"Value\", hue=\"Cohort\", discrete=True, stat=\"probability\", common_norm=False, ax=ax)\n",
    "        ax.set_xlabel(covariate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_covariates(covariates):\n",
    "    covariates = covariates.copy()\n",
    "    covariates[\"Sex\"] = covariates[\"Sex\"].map({\"Male\": 0.0, \"Female\": 1.0})\n",
    "    covariates[\"Education\"] = covariates[\"Education\"].cat.codes.astype(float).replace(-1, np.nan)\n",
    "    return covariates.astype(float)\n",
    "\n",
    "covariates_uke = preprocess_covariates(covariates_uke)\n",
    "covariates_amp = preprocess_covariates(covariates_amp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Treeffuser(seed=42)\n",
    "model.fit(covariates_amp.to_numpy().astype(np.float32), X_amp[GENERATIVE_COLUMNS].to_numpy().astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, x, x_covariates, n_samples: int = 50, seed: int = 42) -> pd.DataFrame:\n",
    "    generated_samples = []\n",
    "    prediction = np.clip(\n",
    "        model.sample(x_covariates, n_samples=n_samples, seed=seed), 0, 100\n",
    "    )\n",
    "\n",
    "    for i, (subject_id, ground_truth) in enumerate(x.iterrows()):\n",
    "        for i_key, (key, value) in enumerate(ground_truth.items()):\n",
    "            if pd.isna(value):\n",
    "                continue\n",
    "\n",
    "            generated_samples.append(\n",
    "                pd.DataFrame.from_dict(\n",
    "                    {\n",
    "                        \"Prediction\": prediction[:, i, i_key],\n",
    "                        \"Ground truth\": value,\n",
    "                        \"Score\": key,\n",
    "                        \"Subject\": subject_id,\n",
    "                        \"Sample ID\": np.arange(n_samples),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "    return pd.concat(generated_samples, ignore_index=True)\n",
    "\n",
    "\n",
    "uke_samples = generate_samples(\n",
    "    model, x_uke[GENERATIVE_COLUMNS], covariates_uke.to_numpy().astype(np.float32), n_samples=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    sns.catplot(\n",
    "        data=uke_samples, x=\"Subject\", y=\"Prediction\", col=\"Score\", col_wrap=3, kind=\"box\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = uke_samples[\n",
    "    (uke_samples[\"Score\"] == \"UPDRS I\") & (uke_samples[\"Subject\"] == 0)\n",
    "]\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    sns.histplot(selection, x=\"Prediction\", binwidth=1, kde=True, discrete=True, stat=\"probability\")\n",
    "\n",
    "print(selection[\"Prediction\"].mean())\n",
    "print(selection[\"Prediction\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_representations(samples: pd.DataFrame):\n",
    "    representations = []\n",
    "    for subject, data in samples.groupby(\"Subject\"):\n",
    "        for score, score_data in data.groupby(\"Score\"):\n",
    "            # mean = score_data[\"Prediction\"].median()\n",
    "            # std = score_data[\"Prediction\"].std()\n",
    "            # mean = score_data[\"Prediction\"].median()\n",
    "            # std = (score_data[\"Prediction\"] - mean).abs().median() + 1e-6\n",
    "            # ground_truth_score = (ground_truth - mean) / std\n",
    "\n",
    "            ground_truth = score_data[\"Ground truth\"].iloc[0]\n",
    "            ground_truth_score = round((score_data[\"Prediction\"] > ground_truth).sum() / len(\n",
    "                score_data\n",
    "            ), 2)\n",
    "            representations.append((subject, score, ground_truth_score))\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame.from_records(representations, columns=[\"Subject\", \"Score\", \"Quantity\"])\n",
    "        .pivot(index=\"Subject\", columns=\"Score\", values=\"Quantity\")\n",
    "        .reset_index()\n",
    "        .set_index(\"Subject\")\n",
    "    )\n",
    "\n",
    "representations = calculate_representations(uke_samples)\n",
    "representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regscores = representations.copy()\n",
    "regscores[\"Normalized PDQ\"] = (x_uke[\"PDQ\"] - y_uke[\"PDQ\"]) / (\n",
    "    x_uke[\"PDQ\"] + y_uke[\"PDQ\"]\n",
    ")\n",
    "regscores = regscores.reset_index().melt(\n",
    "    id_vars=[\"Subject\", \"Normalized PDQ\"], value_name=\"Quantity\"\n",
    ")\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    g = sns.lmplot(\n",
    "        data=regscores,\n",
    "        x=\"Quantity\",\n",
    "        y=\"Normalized PDQ\",\n",
    "        col=\"Score\",\n",
    "        col_wrap=3,\n",
    "        facet_kws=dict(sharex=False, sharey=False),\n",
    "        robust=True,\n",
    "    )\n",
    "    g.refline(y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDITIONS = {\n",
    "    \"demographical data, time, and QoL\": pd.concat(\n",
    "        (covariates_uke[[\"Age\", \"Sex\", \"Time since diagnosis\"]], x_uke[\"PDQ\"], extra_data_uke), axis=1\n",
    "    ),\n",
    "    \"demographical data and scores (QoL included)\": pd.concat(\n",
    "        (covariates_uke[[\"Age\", \"Sex\", \"Time since diagnosis\"]], x_uke, extra_data_uke), axis=1\n",
    "    ),\n",
    "    \"relative scores, time since diagnosis and QoL\": pd.concat(\n",
    "        (representations, x_uke[\"PDQ\"], covariates_uke[[\"Time since diagnosis\"]]), axis=1\n",
    "    ),\n",
    "    \"relative scores, time since diagnosis and surgery\": pd.concat(\n",
    "        (representations, extra_data_uke, covariates_uke[[\"Time since diagnosis\"]]), axis=1\n",
    "    ),\n",
    "    \"relative scores and time\": pd.concat(\n",
    "        (representations, extra_data_uke), axis=1\n",
    "    ),\n",
    "    \"relative scores only\": representations,\n",
    "}\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "y = (x_uke[\"PDQ\"] - y_uke[\"PDQ\"]) / (x_uke[\"PDQ\"] + y_uke[\"PDQ\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for condition, x in CONDITIONS.items():\n",
    "    y_pred = cross_val_predict(\n",
    "        HistGradientBoostingRegressor(learning_rate=0.008377625068989763, max_depth=3, min_samples_leaf=3, max_features=0.5679354907073609),\n",
    "        x,\n",
    "        y,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    predictions.append(\n",
    "        pd.DataFrame(\n",
    "            {\"Normalized PDQ\": y, \"Model prediction\": y_pred, \"Condition\": condition}\n",
    "        )\n",
    "    )\n",
    "\n",
    "predictions = pd.concat(predictions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "predictions = []\n",
    "for condition, x in CONDITIONS.items():\n",
    "    y_pred = cross_val_predict(\n",
    "        Pipeline(\n",
    "            [\n",
    "                (\"imputer\", IterativeImputer(random_state=42)),\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"regressor\", HuberRegressor()),\n",
    "            ]\n",
    "        ),\n",
    "        x,\n",
    "        y,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    predictions.append(\n",
    "        pd.DataFrame(\n",
    "            {\"Normalized PDQ\": y, \"Model prediction\": y_pred, \"Condition\": condition}\n",
    "        )\n",
    "    )\n",
    "\n",
    "predictions = pd.concat(predictions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class TreeffuserCv(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, seed: int = 42):\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = Treeffuser(seed=self.seed)\n",
    "        self.model.fit(X.to_numpy().astype(np.float32), y.to_numpy().astype(np.float32))\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.sample(X.to_numpy().astype(np.float32), n_samples=100, seed=self.seed).mean(axis=0)\n",
    "\n",
    "cv = LeaveOneOut()\n",
    "y = (x_uke[\"PDQ\"] - y_uke[\"PDQ\"]) / (x_uke[\"PDQ\"] + y_uke[\"PDQ\"])\n",
    "\n",
    "y_pred = cross_val_predict(\n",
    "    TreeffuserCv(seed=42),\n",
    "    representations,\n",
    "    y,\n",
    "    cv=cv,\n",
    ")\n",
    "\n",
    "predictions = pd.DataFrame({\n",
    "    \"Normalized PDQ\": y,\n",
    "    \"Model prediction\": y_pred,\n",
    "    \"Condition\": \"Linear model\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(data, **kws):\n",
    "    ax = plt.gca()\n",
    "    #ax.plot(\n",
    "    #    [0, 1], [0, 1], transform=ax.transAxes, color=\"gray\", linestyle=\"--\", alpha=0.3\n",
    "    #)\n",
    "\n",
    "    x_min, x_max = ax.get_xlim()\n",
    "    y_min, y_max = ax.get_ylim()\n",
    "    ax.fill_betweenx(\n",
    "        y=[max(y_min, 0), y_min],\n",
    "        x1=x_min,\n",
    "        x2=x_max,\n",
    "        color=(251 / 255, 212 / 255, 183 / 255),\n",
    "        zorder=-100,\n",
    "    )\n",
    "    ax.fill_betweenx(\n",
    "        y=[0.0, y_max],\n",
    "        x1=x_min,\n",
    "        x2=x_max,\n",
    "        color=(188 / 255, 220 / 255, 190 / 255),\n",
    "        zorder=-100,\n",
    "    )\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    ax.set_xlabel(f\"Model prediction with {data['Condition'].iloc[0]}\")\n",
    "    ax.set_title(\n",
    "        f\"MSE: {mean_squared_error(data['Normalized PDQ'], data['Model prediction']):.3f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "with sns.axes_style(\"white\"):\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    grid = sns.lmplot(\n",
    "        data=predictions,\n",
    "        y=\"Normalized PDQ\",\n",
    "        x=\"Model prediction\",\n",
    "        col=\"Condition\",\n",
    "        robust=True,\n",
    "    )\n",
    "    grid.refline(x=0, y=0)\n",
    "    grid.map_dataframe(annotate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the stochastic component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stochastic_component = pd.read_csv(\"mse.csv\", index_col=\"Seed\")\n",
    "sns.ecdfplot(data=stochastic_component, x=\"MSE\", hue=\"Condition\")\n",
    "\n",
    "round(stochastic_component[\"MSE\"].mean(), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = LeaveOneOut()\n",
    "y = (x_uke[\"PDQ\"] - y_uke[\"PDQ\"]) >= 4.72\n",
    "\n",
    "predictions = []\n",
    "for condition, x in CONDITIONS.items():\n",
    "    y_pred = cross_val_predict(\n",
    "        HistGradientBoostingClassifier(learning_rate=0.008377625068989763, max_depth=3, min_samples_leaf=3, max_features=0.5679354907073609),\n",
    "        x,\n",
    "        y,\n",
    "        cv=cv,\n",
    "    )\n",
    "\n",
    "    predictions.append(\n",
    "        pd.DataFrame({\"Ground truth\": y, \"Prediction\": y_pred, \"Condition\": condition})\n",
    "    )\n",
    "\n",
    "predictions = pd.concat(predictions, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"white\"):\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(predictions.groupby(\"Condition\")), figsize=(12, 4))\n",
    "    for i, ((condition, data), ax) in enumerate(\n",
    "        zip(predictions.groupby(\"Condition\"), axes)\n",
    "    ):\n",
    "        ConfusionMatrixDisplay.from_predictions(\n",
    "            y_true=data[\"Ground truth\"],\n",
    "            y_pred=data[\"Prediction\"],\n",
    "            ax=ax,\n",
    "            colorbar=False,\n",
    "            cmap=\"Reds\",\n",
    "            display_labels=[\"No improvement\", \"Improvement\"],\n",
    "        )\n",
    "        ax.set_title(\n",
    "            f\"{condition}\\nAUC: {roc_auc_score(data['Ground truth'], data['Prediction']):.2f}\"\n",
    "        )\n",
    "        if i > 0:\n",
    "            ax.set_ylabel(\"\")\n",
    "            ax.set_yticklabels([\"\", \"\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
