{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict effect of surgery based upon observational data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from data import load_amp, load_uke\n",
    "import numpy as np\n",
    "from treeffuser import Treeffuser\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay\n",
    "from sklearn.covariance import MinCovDet\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDQ_COLUMNS = [\n",
    "    \"Mobility\",\n",
    "    \"Daily living\",\n",
    "    \"Emotion\",\n",
    "    \"Stigmatization\",\n",
    "    \"Social support\",\n",
    "    \"Cognition\",\n",
    "    \"Communication\",\n",
    "    \"Bodily discomfort\",\n",
    "]\n",
    "COVARIATES = [\"Time since diagnosis\", \"Age\", \"Sex\"]\n",
    "EXTRA_COVARIATES = [\"UPDRS I\", \"UPDRS II\", \"UPDRS III\", \"UPDRS IV\", \"MoCA\"]\n",
    "SEED = 39\n",
    "\n",
    "\n",
    "def cast_to_float(data):\n",
    "    for column in data.columns:\n",
    "        data[column] = pd.to_numeric(data[column], errors=\"coerce\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_covariates(data):\n",
    "    data = data.copy()\n",
    "    data[\"Sex\"] = data[\"Sex\"].map({\"Male\": 0.0, \"Female\": 1.0})\n",
    "    data = cast_to_float(data)\n",
    "    return data\n",
    "\n",
    "\n",
    "def parse_data(y, covariates):\n",
    "    data = pd.concat(\n",
    "        (y[[\"Participant\", \"Study\", \"Visit ID\", *PDQ_COLUMNS, *EXTRA_COVARIATES]], covariates[COVARIATES]), axis=1\n",
    "    ).dropna(thresh=4 + len(COVARIATES) + len(EXTRA_COVARIATES))\n",
    "    data[\"Visit ID\"] = data[\"Visit ID\"].str[1:].astype(int)\n",
    "    data = data[data[\"Study\"] != \"HBS\"]\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    extra_data = []\n",
    "    \n",
    "    for _, data in data.sort_values(\n",
    "        [\"Participant\", \"Visit ID\"], ascending=True\n",
    "    ).groupby([\"Participant\"]):\n",
    "        for iloc, (_, row) in enumerate(data.iterrows()):\n",
    "            if iloc > 0:\n",
    "                previous_row = data.iloc[iloc - 1]\n",
    "                previous_row = previous_row[PDQ_COLUMNS].to_list() + [\n",
    "                    (row[\"Visit ID\"] - previous_row[\"Visit ID\"]) / 12.0\n",
    "                ]\n",
    "            else:\n",
    "                previous_row = [np.nan] * (len(PDQ_COLUMNS) + 1)\n",
    "\n",
    "            X.append(previous_row + row[COVARIATES].to_list() + row[EXTRA_COVARIATES].to_list())\n",
    "            y.append(row[PDQ_COLUMNS])\n",
    "            extra_data.append([row[\"Study\"]])\n",
    "            \n",
    "    return preprocess_covariates(\n",
    "        pd.DataFrame(X, columns=PDQ_COLUMNS + [\"Time since last visit\"] + COVARIATES + EXTRA_COVARIATES)\n",
    "    ), cast_to_float(pd.DataFrame(y, columns=PDQ_COLUMNS).reset_index(drop=True)), pd.DataFrame(extra_data, columns=[\"Study\"])\n",
    "\n",
    "# Load the AMP data\n",
    "X_amp, covariates_amp = load_amp(\n",
    "    \"/workspaces/de.uke.iam.parkinson.vae_longitudinal/data/updrs_amp_all.csv\",\n",
    "    sample_one_measurement_per_subject=False,\n",
    ")\n",
    "X_amp, y_amp, extra_data_amp = parse_data(X_amp, covariates_amp)\n",
    "\n",
    "# Load the UKE data\n",
    "X_uke, covariates_uke, extra_data_uke, y_uke = load_uke(\n",
    "    \"/workspaces/de.uke.iam.parkinson.vae_longitudinal/data/pdq_uke_new.csv\",\n",
    "    PDQ_COLUMNS + EXTRA_COVARIATES,\n",
    ")\n",
    "\n",
    "X_uke = pd.concat(\n",
    "    (\n",
    "        X_uke,\n",
    "        extra_data_uke[[\"Time since last test\"]].rename(\n",
    "            columns={\"Time since last test\": \"Time since last visit\"}\n",
    "        ),\n",
    "        covariates_uke[COVARIATES],\n",
    "    ),\n",
    "    axis=1,\n",
    ")\n",
    "full_measurements_uke = pd.isna(X_uke).sum(axis=1) < 4\n",
    "X_uke = preprocess_covariates(X_uke)[full_measurements_uke]\n",
    "covariates_uke = covariates_uke[full_measurements_uke]\n",
    "extra_data_uke = extra_data_uke[full_measurements_uke]\n",
    "y_uke = y_uke[full_measurements_uke]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import properscoring\n",
    "\n",
    "INDICES_TEST_SET = extra_data_amp[\"Study\"] == \"Sure\"\n",
    "\n",
    "X_amp_train = X_amp[~INDICES_TEST_SET]\n",
    "y_amp_train = y_amp[~INDICES_TEST_SET]\n",
    "X_amp_test = X_amp[INDICES_TEST_SET]s\n",
    "y_amp_test = y_amp[INDICES_TEST_SET]\n",
    "\n",
    "model = Treeffuser(seed=SEED)\n",
    "model.fit(X_amp_train.to_numpy().astype(np.float32), y_amp_train.to_numpy().astype(np.float32))\n",
    "y_samples = model.sample(X_amp_test.to_numpy().astype(np.float32), 100, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results = pd.DataFrame(properscoring.crps_ensemble(\n",
    "    y_amp_test.to_numpy().astype(np.float32),\n",
    "    np.clip(y_samples, 0, 100),\n",
    "    axis=0,\n",
    "), columns=PDQ_COLUMNS, index=X_amp_test.index)\n",
    "results[\"Covariates only\"] = pd.isna(X_amp_test[PDQ_COLUMNS]).sum(axis=1) == len(PDQ_COLUMNS)\n",
    "results = results.melt(id_vars=\"Covariates only\", var_name=\"Subscore\", value_name=\"CRPS\")\n",
    "sns.catplot(data=results, x=\"Subscore\", y=\"CRPS\", hue=\"Covariates only\", kind=\"point\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the generative model and calculate the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_data = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"pre_pdq\": X_uke[PDQ_COLUMNS].mean(axis=1),\n",
    "        \"updrs_iii_change\": extra_data_uke[\"UPDRS III: Change\"],\n",
    "        \"diagnosis_time\": covariates_uke[\"Time since diagnosis\"],\n",
    "        \"improvement\": (X_uke[PDQ_COLUMNS].mean(axis=1) - y_uke[PDQ_COLUMNS].mean(axis=1) > 10.9).astype(float),\n",
    "    }\n",
    ")\n",
    "\n",
    "baseline = smf.logit(\n",
    "    \"improvement ~ pre_pdq + updrs_iii_change + diagnosis_time\", data=baseline_data\n",
    ").fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, covariates, n_samples: int = 500, seed: int = 42):\n",
    "    predicted = np.clip(\n",
    "        model.sample(\n",
    "            covariates.to_numpy().astype(np.float32), n_samples=n_samples, seed=seed\n",
    "        ),\n",
    "        0,\n",
    "        100,\n",
    "    )\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(predicted[:, i, :], columns=PDQ_COLUMNS).assign(\n",
    "                Subject=subject_id, Sample=list(range(predicted.shape[0]))\n",
    "            )\n",
    "            for i, (subject_id, _) in enumerate(covariates.iterrows())\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "model = Treeffuser(seed=SEED)\n",
    "model.fit(X_amp.to_numpy().astype(np.float32), y_amp.to_numpy().astype(np.float32))\n",
    "X_uke_masked = X_uke.copy()\n",
    "X_uke_masked[PDQ_COLUMNS] = np.nan\n",
    "X_uke_predicted = generate_samples(model, X_uke_masked, n_samples=500, seed=SEED)\n",
    "y_uke_predicted = generate_samples(model, X_uke, n_samples=500, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate different \"simple\" predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_mahalanobis = []\n",
    "for (subject_id, ground_truth) in X_uke.iterrows():\n",
    "    robust_cov = MinCovDet(random_state=SEED).fit(X_uke_predicted[X_uke_predicted[\"Subject\"] == subject_id][PDQ_COLUMNS].to_numpy())\n",
    "    distance = robust_cov.mahalanobis(\n",
    "        ground_truth[PDQ_COLUMNS].to_numpy().reshape(1, -1)\n",
    "    )[0] ** (0.33)\n",
    "    samples_mahalanobis.append((subject_id, distance))\n",
    "\n",
    "samples_mahalanobis = pd.DataFrame.from_records(\n",
    "    samples_mahalanobis, columns=[\"Subject ID\", \"mahalanobis\"]\n",
    ").set_index(\"Subject ID\")\n",
    "samples_mahalanobis[\"improvement\"] = (\n",
    "    (X_uke[PDQ_COLUMNS].mean(axis=1) - y_uke[PDQ_COLUMNS].mean(axis=1)) > 10.9\n",
    ").astype(float)\n",
    "samples_mahalanobis[\"pre_pdq\"] = X_uke[PDQ_COLUMNS].mean(axis=1)\n",
    "\n",
    "mahalanobis = smf.logit(\"improvement ~ mahalanobis\", data=samples_mahalanobis).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_improvement_ratio = []\n",
    "for (subject_id, ground_truth) in X_uke.iterrows():\n",
    "    difference = ((ground_truth[PDQ_COLUMNS].mean() - y_uke_predicted[y_uke_predicted[\"Subject\"] == subject_id][PDQ_COLUMNS].mean(axis=1)) > 10.9).mean()\n",
    "    samples_improvement_ratio.append((subject_id, difference))\n",
    "    \n",
    "samples_improvement_ratio = pd.DataFrame.from_records(\n",
    "    samples_improvement_ratio, columns=[\"Subject ID\", \"chance_for_improvement\"]\n",
    ").set_index(\"Subject ID\")\n",
    "samples_improvement_ratio[\"improvement\"] = (\n",
    "    (X_uke[PDQ_COLUMNS].mean(axis=1) - y_uke[PDQ_COLUMNS].mean(axis=1)) > 10.9\n",
    ").astype(float)\n",
    "samples_improvement_ratio[\"pre_pdq\"] = X_uke[PDQ_COLUMNS].mean(axis=1)\n",
    "\n",
    "improvement_ratio = smf.logit(\"improvement ~ chance_for_improvement\", data=samples_improvement_ratio).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdq_only = smf.logit(\"improvement ~ pre_pdq\", data=samples_mahalanobis).fit()\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        samples_mahalanobis[\"improvement\"],\n",
    "        pdq_only.predict(samples_mahalanobis),\n",
    "        name=\"PDQ only\",\n",
    "    )\n",
    "\n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        baseline_data[\"improvement\"],\n",
    "        baseline.predict(baseline_data),\n",
    "        name=\"Baseline\",\n",
    "        ax=viz.ax_,\n",
    "    )\n",
    "    \n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        samples_mahalanobis[\"improvement\"],\n",
    "        mahalanobis.predict(samples_mahalanobis),\n",
    "        name=\"Mahalanobis\",\n",
    "        ax=viz.ax_,\n",
    "    )\n",
    "    \n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        samples_improvement_ratio[\"improvement\"],\n",
    "        improvement_ratio.predict(samples_improvement_ratio),\n",
    "        name=\"Improvement ratio\",\n",
    "        ax=viz.ax_,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the differences between observed and predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_difference_pre = pd.concat(\n",
    "    [\n",
    "        ((X_uke_predicted[X_uke_predicted[\"Subject\"] == subject][PDQ_COLUMNS]) - data[PDQ_COLUMNS]).assign(\n",
    "            Subject=subject,\n",
    "            Sample=X_uke_predicted[\"Sample\"]\n",
    "        )\n",
    "        for subject, data in y_uke.iterrows()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").melt(id_vars=[\"Subject\", \"Sample\"], var_name=\"Subscore\", value_name=\"Difference\")\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    g = sns.catplot(\n",
    "        relative_difference_pre.groupby([\"Subscore\", \"Subject\"]).mean().reset_index(),\n",
    "        x=\"Subscore\",\n",
    "        y=\"Difference\",\n",
    "        hue=\"Subscore\",\n",
    "        height=6,\n",
    "        aspect=2,\n",
    "        # inner=\"box\",\n",
    "        # kind=\"violin\",\n",
    "        # kind=\"strip\"\n",
    "        kind=\"box\",\n",
    "    )\n",
    "    g.map_dataframe(sns.stripplot, x=\"Subscore\", y=\"Difference\", palette=[\"#404040\"], alpha=0.6)\n",
    "    g.refline(y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_difference_post = pd.concat(\n",
    "    [\n",
    "        ((y_uke_predicted[y_uke_predicted[\"Subject\"] == subject][PDQ_COLUMNS]) - data[PDQ_COLUMNS]).assign(\n",
    "            Subject=subject,\n",
    "            Sample=y_uke_predicted[\"Sample\"]\n",
    "        )\n",
    "        for subject, data in y_uke.iterrows()\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ").melt(id_vars=[\"Subject\", \"Sample\"], var_name=\"Subscore\", value_name=\"Difference\")\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    g = sns.catplot(\n",
    "        relative_difference_post.groupby([\"Subscore\", \"Subject\"]).mean().reset_index(),\n",
    "        x=\"Subscore\",\n",
    "        y=\"Difference\",\n",
    "        hue=\"Subscore\",\n",
    "        height=6,\n",
    "        aspect=2,\n",
    "        # inner=\"box\",\n",
    "        # kind=\"violin\",\n",
    "        # kind=\"strip\"\n",
    "        kind=\"box\"\n",
    "    )\n",
    "    g.map_dataframe(sns.stripplot, x=\"Subscore\", y=\"Difference\", palette=[\"#404040\"], alpha=0.6)\n",
    "    g.refline(y=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate difference to baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_diff_X_uke = relative_difference_pre.groupby([\"Subscore\", \"Subject\"]).mean().reset_index().drop(columns=[\"Sample\"]).pivot(index=[\"Subject\"], columns=[\"Subscore\"], values=\"Difference\")\n",
    "median_diff_y_uke = relative_difference_post.groupby([\"Subscore\", \"Subject\"]).mean().reset_index().drop(columns=[\"Sample\"]).pivot(index=[\"Subject\"], columns=[\"Subscore\"], values=\"Difference\")\n",
    "\n",
    "pre_post_comparison = median_diff_X_uke.reset_index().melt(id_vars=[\"Subject\"], var_name=\"Subscore\", value_name=\"Difference\").set_index([\"Subject\", \"Subscore\"]).rename(columns={\"Difference\": \"Pre\"}).join(median_diff_y_uke.reset_index().melt(id_vars=[\"Subject\"], var_name=\"Subscore\", value_name=\"Difference\").set_index([\"Subject\", \"Subscore\"]).rename(columns={\"Difference\": \"Post\"})).reset_index()\n",
    "\n",
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    fig = sns.lmplot(pre_post_comparison, x=\"Pre\", y=\"Post\", col=\"Subscore\", col_wrap=3, order=1, robust=False)\n",
    "    fig.refline(x=0, y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uke_predicted_adjusted = y_uke_predicted.copy()\n",
    "for row, data in median_diff_X_uke.iterrows():\n",
    "    y_uke_predicted_adjusted.loc[y_uke_predicted_adjusted[\"Subject\"] == row, PDQ_COLUMNS] -= data.to_numpy()\n",
    "y_uke_predicted_adjusted[PDQ_COLUMNS] = y_uke_predicted_adjusted[PDQ_COLUMNS].clip(0, 100)\n",
    "y_uke_predicted_adjusted[\"Post PDQ: Predicted\"] = y_uke_predicted_adjusted[PDQ_COLUMNS].mean(axis=1)\n",
    "y_uke_predicted_adjusted = y_uke_predicted_adjusted.join(pd.DataFrame(X_uke[PDQ_COLUMNS].mean(axis=1).rename(\"Pre PDQ\")), on=\"Subject\")\n",
    "y_uke_predicted_adjusted[\"Improvement: Predicted\"] = (y_uke_predicted_adjusted[\"Pre PDQ\"] - y_uke_predicted_adjusted[\"Post PDQ: Predicted\"]) > 10.9\n",
    "\n",
    "samples_constant_adjustment = pd.DataFrame.from_dict({\n",
    "    \"predicted_improvement\": y_uke_predicted_adjusted.groupby(\"Subject\")[\"Improvement: Predicted\"].mean(),\n",
    "    \"observed_change\": (X_uke[PDQ_COLUMNS].mean(axis=1) - y_uke[PDQ_COLUMNS].mean(axis=1)) \n",
    "})\n",
    "samples_constant_adjustment[\"improvement\"] = (samples_constant_adjustment[\"observed_change\"] > 10.9).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "\n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        baseline_data[\"improvement\"],\n",
    "        baseline.predict(baseline_data),\n",
    "        name=\"Baseline\",\n",
    "    )\n",
    "\n",
    "    viz = RocCurveDisplay.from_predictions(\n",
    "        samples_constant_adjustment[\"improvement\"],\n",
    "        samples_constant_adjustment[\"predicted_improvement\"],\n",
    "        name=\"Proposed\",\n",
    "        ax=viz.ax_\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"):\n",
    "    sns.set_context(\"paper\")\n",
    "    sns.scatterplot(samples_constant_adjustment, x=\"predicted_improvement\", y=\"observed_change\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
