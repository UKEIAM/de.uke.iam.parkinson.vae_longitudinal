{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from vae import VariationAutoencoderModule, WassersteinLoss, MultiCategoricalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpdrsData(Dataset):\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        data = pd.read_csv(path, sep=\"\\t\").sort_values([\"PatientID\", \"Age\"])\n",
    "        measurements = (\n",
    "            data[[column for column in data.columns if column.startswith(\"3.\")]]\n",
    "            .dropna()\n",
    "            .astype(int)\n",
    "        )\n",
    "        self.covariates = data.loc[\n",
    "            measurements.index,\n",
    "            [\n",
    "                \"PatientID\",\n",
    "                \"Age\",\n",
    "                \"Deep brain stimulation available\",\n",
    "                \"Deep brain stimulation\",\n",
    "                \"Medication\",\n",
    "            ],\n",
    "        ].reset_index(drop=True)\n",
    "        self.measurements = torch.tensor(measurements.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.measurements[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.measurements)\n",
    "\n",
    "    @property\n",
    "    def participant_covariate(self) -> str:\n",
    "        return \"PatientID\"\n",
    "\n",
    "\n",
    "class UpdrsDataQoL(Dataset):\n",
    "    COLUMNS = [f\"UPDRS 1.{i}\" for i in range(1, 14)] + [\n",
    "        f\"UPDRS 2.{i}\" for i in range(1, 14)\n",
    "    ]\n",
    "\n",
    "    def __init__(self, path):\n",
    "        super().__init__()\n",
    "        data = pd.read_csv(path, sep=\",\").sort_values([\"Participant\", \"Age\"])\n",
    "        measurements = data[UpdrsDataQoL.COLUMNS].dropna().astype(int)\n",
    "        self.covariates = data.loc[\n",
    "            measurements.index,\n",
    "            [\"Participant\", \"Age\"],\n",
    "        ].reset_index(drop=True)\n",
    "        self.measurements = torch.tensor(measurements.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.measurements[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.measurements)\n",
    "\n",
    "    @property\n",
    "    def participant_covariate(self) -> str:\n",
    "        return \"Participant\"\n",
    "\n",
    "\n",
    "class UpdrsDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: Dataset,\n",
    "        percentage_subjects_in_valid_dataset: float,\n",
    "        batch_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert 0 < percentage_subjects_in_valid_dataset <= 1\n",
    "\n",
    "        self.data = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if percentage_subjects_in_valid_dataset < 1:\n",
    "            patients = self.data.covariates[dataset.participant_covariate].unique()\n",
    "            num_patients_valid = int(\n",
    "                len(patients) * percentage_subjects_in_valid_dataset\n",
    "            )\n",
    "            first_patient_valid = len(patients) - num_patients_valid\n",
    "            # Find the index of the first patient in valid set\n",
    "            self.val_start = self.data.covariates[\n",
    "                self.data.covariates[dataset.participant_covariate]\n",
    "                == patients[first_patient_valid]\n",
    "            ].index[0]\n",
    "        else:\n",
    "            self.val_start = 0\n",
    "\n",
    "    def calculate_class_weights(self):\n",
    "        return torch.tensor(\n",
    "            compute_class_weight(\n",
    "                \"balanced\",\n",
    "                classes=range(5),\n",
    "                y=self.data.measurements[: self.val_start].flatten().long().numpy(),\n",
    "            )\n",
    "        ).float()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        if self.val_start == 0:\n",
    "            raise ValueError(\"Only the validation set is used.\")\n",
    "        return DataLoader(\n",
    "            Subset(self.data, range(0, self.val_start)),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "            num_workers=8,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            Subset(self.data, range(self.val_start, len(self.data))),\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            drop_last=False,\n",
    "            num_workers=4,\n",
    "        )\n",
    "\n",
    "\n",
    "data = UpdrsDataQoL(\n",
    "    \"/workspaces/de.uke.iam.parkinson.vae_longitudinal/data/updrs_amp.csv\"\n",
    ")\n",
    "data_module = UpdrsDataModule(\n",
    "    data,\n",
    "    percentage_subjects_in_valid_dataset=0.2,\n",
    "    batch_size=512,\n",
    ")\n",
    "print(len(data_module.train_dataloader()))\n",
    "print(len(data_module.val_dataloader()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"updrs_qol_vae_new\"\n",
    "\n",
    "reconstruction_loss = MultiCategoricalLoss(\n",
    "    n_values=len(UpdrsDataQoL.COLUMNS),\n",
    "    n_classes=5,\n",
    "    is_categorical=False,\n",
    "    is_ordinal=True,\n",
    "    weight=data_module.calculate_class_weights().to(\"cuda\"),\n",
    ")\n",
    "#generative_loss = KullbackLeiblerLoss(beta=1.0)\n",
    "generative_loss = WassersteinLoss(reg_weight=100, kernel_type=\"imq\", z_var=2.0)\n",
    "model = VariationAutoencoderModule(\n",
    "    reconstruction_loss, generative_loss, [64, 48, 32, 16], patience=80, learning_rate=1e-3, dropout=0.05\n",
    ")\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",\n",
    "    filename=NAME,\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor=\"val_concordance\",\n",
    "    mode=\"max\",\n",
    ")\n",
    "early_stopping = EarlyStopping(monitor=\"val_concordance\", patience=120, mode=\"max\")\n",
    "logger = TensorBoardLogger(\"logs\", name=NAME)\n",
    "\n",
    "# Initialize the PyTorch Lightning trainer\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=1000, callbacks=[early_stopping], logger=logger, log_every_n_steps=6\n",
    ")\n",
    "\n",
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VariationAutoencoderModule.load_from_checkpoint(\n",
    "    \"/workspaces/de.uke.iam.parkinson.vae_longitudinal/src/logs/updrs_qol_vae/version_1/checkpoints/epoch=431-step=2592.ckpt\"\n",
    ").model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "def load_testdata(path: str) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    data = pd.read_csv(\n",
    "        path,\n",
    "        sep=\",\",\n",
    "        na_values=[\n",
    "            \"Keine_Angabe\",\n",
    "            \"Nicht_durchgef√ºhrt\",\n",
    "            \"Keine_Angaben\",\n",
    "            \"Keine_angabe\",\n",
    "        ],\n",
    "    )\n",
    "    pdq_columns = [column for column in data.columns if column.startswith(\"PDQ39 \")]\n",
    "    updrs_columns = [\n",
    "        column\n",
    "        for column in data.columns\n",
    "        if column.startswith(\"UPDRS 1.\") or column.startswith(\"UPDRS 2.\")\n",
    "    ]\n",
    "    data = data[pdq_columns + updrs_columns].dropna().reset_index(drop=True)\n",
    "    return data[updrs_columns], data[pdq_columns]\n",
    "\n",
    "\n",
    "test_updrs, test_pdq = load_testdata(\n",
    "    \"/workspaces/de.uke.iam.parkinson.vae_longitudinal/data/pdq_uke_new.csv\"\n",
    ")\n",
    "\n",
    "ground_truth = next(iter(data_module.val_dataloader()))\n",
    "ground_truth_sum = ground_truth.sum(axis=-1).to(\"cuda\")\n",
    "reconstruction_sum = model(ground_truth.to(\"cuda\")).x_recon.sum(axis=-1)\n",
    "\n",
    "print(\n",
    "    F.l1_loss(\n",
    "        input=ground_truth.to(\"cuda\"),\n",
    "        target=model(ground_truth.to(\"cuda\")).x_recon,\n",
    "        reduction=\"none\",\n",
    "    )\n",
    "    .sum(axis=-1)\n",
    "    .mean()\n",
    "    / (ground_truth.shape[-1])\n",
    ")\n",
    "print(\n",
    "    (\n",
    "        (ground_truth.to(\"cuda\") != model(ground_truth.to(\"cuda\")).x_recon).sum(axis=-1)\n",
    "        / ground_truth.shape[-1]\n",
    "    ).median()\n",
    ")\n",
    "print(\n",
    "    torchmetrics.functional.concordance_corrcoef(\n",
    "        target=ground_truth_sum.to(torch.float),\n",
    "        preds=reconstruction_sum.to(torch.float),\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
